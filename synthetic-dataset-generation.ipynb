{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30636,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip install transformers compel accelerate gdown diffusers pyrebase4 -U > /dev/null\n",
    "!gdown 1IohKG23i468616bPHBkDHiBnZvmPW3m5 > /dev/null #нужный csv с новыми промптами, которых нет в базе данных\n",
    "!gdown 1pF1u8mekNs_z_KvFIJRTdqhlFHm1lp5n > /dev/null"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2024-02-16T15:32:41.455472Z",
     "iopub.execute_input": "2024-02-16T15:32:41.455770Z",
     "iopub.status.idle": "2024-02-16T15:33:20.049883Z",
     "shell.execute_reply.started": "2024-02-16T15:32:41.455744Z",
     "shell.execute_reply": "2024-02-16T15:33:20.048889Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image, ImageDraw, ImageFont, ImageChops\n",
    "from scipy.spatial.qhull import QhullError\n",
    "from scipy import spatial\n",
    "spatial.QhullError = QhullError\n",
    "from tqdm.auto import tqdm\n",
    "import io\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import zlib\n",
    "import requests\n",
    "from transformers import AutoProcessor, AutoModel\n",
    "from diffusers import StableDiffusionXLPipeline, UNet2DConditionModel\n",
    "import threading\n",
    "import os\n",
    "import shutil\n",
    "from torchvision.transforms.functional import pil_to_tensor\n",
    "import pyrebase\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "from compel import Compel, ReturnedEmbeddingsType"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-16T15:33:20.051980Z",
     "iopub.execute_input": "2024-02-16T15:33:20.052300Z",
     "iopub.status.idle": "2024-02-16T15:33:38.654347Z",
     "shell.execute_reply.started": "2024-02-16T15:33:20.052274Z",
     "shell.execute_reply": "2024-02-16T15:33:38.653511Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def load_db():\n",
    "    config_path = 'firebase_auth.json'\n",
    "    assert os.path.exists(config_path)\n",
    "\n",
    "    config = {\n",
    "      \"apiKey\": \"AIzaSyBnWywH3ZswQNyLblBohBAp__f_F2myt5M\",\n",
    "      \"authDomain\": \"datasetcollect-81ac0.firebaseapp.com\",\n",
    "      \"databaseURL\": \"https://datasetcollect-81ac0-default-rtdb.firebaseio.com\",\n",
    "      \"storageBucket\": \"datasetcollect-81ac0.appspot.com\",\n",
    "      \"ServiceAccount\": config_path,\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "    firebase = pyrebase.initialize_app(config)\n",
    "    db = firebase.database()\n",
    "    return db\n",
    "\n",
    "db = load_db()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-16T15:33:38.655416Z",
     "iopub.execute_input": "2024-02-16T15:33:38.655940Z",
     "iopub.status.idle": "2024-02-16T15:33:38.665244Z",
     "shell.execute_reply.started": "2024-02-16T15:33:38.655913Z",
     "shell.execute_reply": "2024-02-16T15:33:38.664224Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "GEN_BATCH_SIZE = 100\n",
    "\n",
    "def set_generated(prompt_id):\n",
    "    db.child(\"prompts_raw\").child(prompt_id).update({\n",
    "        \"is_generated\": True\n",
    "    })\n",
    "\n",
    "def load_not_generated_db_prompts():\n",
    "    not_generated_db_prompts = []\n",
    "    prompts_table = db.child(\"prompts_raw\")\n",
    "\n",
    "    for prompt_record in prompts_table.get().val().items():\n",
    "        prompt_id, prompt, is_generated = prompt_record[0], prompt_record[1][\"prompt\"], prompt_record[1][\"is_generated\"]\n",
    "        if not is_generated:\n",
    "            not_generated_db_prompts.append(prompt)\n",
    "            set_generated(prompt_id)\n",
    "        if len(not_generated_db_prompts) >= GEN_BATCH_SIZE:\n",
    "            break\n",
    "\n",
    "    return not_generated_db_prompts\n",
    "\n",
    "prompts = load_not_generated_db_prompts()\n",
    "print(prompts)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-16T15:38:42.974360Z",
     "iopub.execute_input": "2024-02-16T15:38:42.975300Z",
     "iopub.status.idle": "2024-02-16T15:38:43.019055Z",
     "shell.execute_reply.started": "2024-02-16T15:38:42.975268Z",
     "shell.execute_reply": "2024-02-16T15:38:43.018073Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def drop_dots(prompts):\n",
    "    for i in range(len(prompts)):\n",
    "        if prompts[i][-1] == \".\":\n",
    "            prompts[i] = prompts[i][:-1]\n",
    "    return prompts\n",
    "\n",
    "prompts = drop_dots(prompts)\n",
    "print(prompts)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_id = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "unet_id = \"mhdang/dpo-sdxl-text2image-v1\"\n",
    "\n",
    "pipe1 = StableDiffusionXLPipeline.from_pretrained(model_id, torch_dtype=torch.float16, variant=\"fp16\",\n",
    "                                                  use_safetensors=True).to(\"cuda:0\")\n",
    "unet1 = UNet2DConditionModel.from_pretrained(unet_id, subfolder=\"unet\", torch_dtype=torch.float16).to('cuda:0')\n",
    "pipe1.unet = unet1\n",
    "pipe1 = pipe1.to(\"cuda:0\")\n",
    "\n",
    "pipe2 = StableDiffusionXLPipeline.from_pretrained(model_id, torch_dtype=torch.float16, variant=\"fp16\",\n",
    "                                                  use_safetensors=True).to(\"cuda:1\")\n",
    "unet2 = UNet2DConditionModel.from_pretrained(unet_id, subfolder=\"unet\", torch_dtype=torch.float16).to('cuda:1')\n",
    "pipe2.unet = unet2\n",
    "pipe2 = pipe2.to(\"cuda:1\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "blip_version = \"noamrot/FuseCap\"\n",
    "\n",
    "blip_processor = BlipProcessor.from_pretrained(blip_version)\n",
    "blip_model1 = BlipForConditionalGeneration.from_pretrained(blip_version).to(\"cuda:0\")\n",
    "\n",
    "blip_model2 = BlipForConditionalGeneration.from_pretrained(blip_version).to(\"cuda:1\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-16T15:41:32.962802Z",
     "iopub.execute_input": "2024-02-16T15:41:32.963123Z",
     "iopub.status.idle": "2024-02-16T15:41:41.542502Z",
     "shell.execute_reply.started": "2024-02-16T15:41:32.963097Z",
     "shell.execute_reply": "2024-02-16T15:41:41.541442Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def generate_caption(raw_image, device):\n",
    "    \n",
    "    inputs = blip_processor(raw_image, return_tensors=\"pt\").to(\n",
    "        device)\n",
    "    if device == 'cuda:0':\n",
    "        out = blip_model1.generate(**inputs)\n",
    "    else:\n",
    "        out = blip_model2.generate(**inputs)\n",
    "    caption = blip_processor.decode(out[0], skip_special_tokens=True)\n",
    "    return caption.strip()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-16T15:41:41.543764Z",
     "iopub.execute_input": "2024-02-16T15:41:41.544084Z",
     "iopub.status.idle": "2024-02-16T15:41:41.552678Z",
     "shell.execute_reply.started": "2024-02-16T15:41:41.544059Z",
     "shell.execute_reply": "2024-02-16T15:41:41.551836Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "base_compel1 = Compel(\n",
    "    tokenizer=[pipe1.tokenizer, pipe1.tokenizer_2],\n",
    "    text_encoder=[pipe1.text_encoder, pipe1.text_encoder_2],\n",
    "    returned_embeddings_type=ReturnedEmbeddingsType.PENULTIMATE_HIDDEN_STATES_NON_NORMALIZED,\n",
    "    requires_pooled=[False, True]\n",
    ")\n",
    "\n",
    "base_compel2 = Compel(\n",
    "    tokenizer=[pipe2.tokenizer, pipe2.tokenizer_2],\n",
    "    text_encoder=[pipe2.text_encoder, pipe2.text_encoder_2],\n",
    "    returned_embeddings_type=ReturnedEmbeddingsType.PENULTIMATE_HIDDEN_STATES_NON_NORMALIZED,\n",
    "    requires_pooled=[False, True]\n",
    ")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-16T15:41:41.555131Z",
     "iopub.execute_input": "2024-02-16T15:41:41.555498Z",
     "iopub.status.idle": "2024-02-16T15:41:41.687325Z",
     "shell.execute_reply.started": "2024-02-16T15:41:41.555465Z",
     "shell.execute_reply": "2024-02-16T15:41:41.686390Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def gen_sticker_with_mixed_prompts(prompt_sticker, caption, generator, device, sticker_cond = 'a cartoon sticker', x1=1.0, x2=0.55,x3=1.0):\n",
    "    prompt = f'\"{prompt_sticker}\", \"{caption}\", \"{sticker_cond}\").blend({x1}, {x2}, {x3})'\n",
    "    \n",
    "    if device == 'cuda:0':\n",
    "    \n",
    "        base_positive_prompt_embeds, base_positive_prompt_pooled = base_compel1(prompt)\n",
    "        base_negative_prompt_embeds, base_negative_prompt_pooled = base_compel1('low-quality')\n",
    "        base_positive_prompt_embeds, base_negative_prompt_embeds = base_compel1.pad_conditioning_tensors_to_same_length([\n",
    "            base_positive_prompt_embeds, base_negative_prompt_embeds\n",
    "        ])\n",
    "\n",
    "        image_sticker_new = pipe1(prompt_embeds=base_positive_prompt_embeds,\n",
    "            pooled_prompt_embeds=base_positive_prompt_pooled,\n",
    "            negative_prompt_embeds=base_negative_prompt_embeds,\n",
    "            negative_pooled_prompt_embeds=base_negative_prompt_pooled,\n",
    "            output_type=\"pil\", guidance_scale=5, generator=generator).images[0]\n",
    "    else:\n",
    "            \n",
    "        base_positive_prompt_embeds, base_positive_prompt_pooled = base_compel2(prompt)\n",
    "        base_negative_prompt_embeds, base_negative_prompt_pooled = base_compel2('low-quality')\n",
    "        base_positive_prompt_embeds, base_negative_prompt_embeds = base_compel2.pad_conditioning_tensors_to_same_length([\n",
    "            base_positive_prompt_embeds, base_negative_prompt_embeds\n",
    "        ])\n",
    "\n",
    "        image_sticker_new = pipe2(prompt_embeds=base_positive_prompt_embeds,\n",
    "            pooled_prompt_embeds=base_positive_prompt_pooled,\n",
    "            negative_prompt_embeds=base_negative_prompt_embeds,\n",
    "            negative_pooled_prompt_embeds=base_negative_prompt_pooled,\n",
    "            output_type=\"pil\", guidance_scale=5, generator=generator).images[0]\n",
    "        \n",
    "        \n",
    "    return image_sticker_new\n",
    "\n",
    "\n",
    "def generate_seed_from_prompt(prompt):\n",
    "    return zlib.adler32(prompt.encode())\n",
    "\n",
    "def get_rand_gen(prompt, device):\n",
    "    rnd_seed = generate_seed_from_prompt(prompt)\n",
    "    return torch.Generator(device).manual_seed(rnd_seed), rnd_seed\n",
    "\n",
    "def get_pair_data(prompt_sticker, device):\n",
    "    prompt = prompt_sticker.replace('A sticker', 'A photo', 1)\n",
    "    prompt += ', 8k, fullHD, realistic photography.'\n",
    "    prompt_sticker += ', cartoon style.'\n",
    "    generator, rnd_seed = get_rand_gen(prompt, device)\n",
    "    \n",
    "    if device == 'cuda:0':\n",
    "        image = pipe1(prompt, guidance_scale=5, generator=generator).images[0]\n",
    "        img_cap = generate_caption(image, device)\n",
    "        image_sticker1 = pipe1(prompt_sticker, guidance_scale=5, generator=generator).images[0]\n",
    "    else:\n",
    "        image = pipe2(prompt, guidance_scale=5, generator=generator).images[0]\n",
    "        img_cap = generate_caption(image, device)\n",
    "        image_sticker1 = pipe2(prompt_sticker, guidance_scale=5, generator=generator).images[0]\n",
    "        \n",
    "    image_sticker2 = gen_sticker_with_mixed_prompts(prompt_sticker, img_cap, generator, device)\n",
    "\n",
    "    return (prompt_sticker,image_sticker1,image_sticker2, prompt,image,rnd_seed, img_cap)\n",
    "\n",
    "\n",
    "def runner(prompt_stickers, device):\n",
    "    global max_results, result\n",
    "    \n",
    "    count = 0\n",
    "    for prompt_sticker in tqdm(prompt_stickers):\n",
    "        data = get_pair_data(prompt_sticker, device)\n",
    "        count += 1\n",
    "        result.append(data)\n",
    "                \n",
    "        if count == max_results // 2:\n",
    "            break\n",
    "    \n",
    "def main(prompt_stickers):\n",
    "    try:\n",
    "        p1, p2 = prompt_stickers[:len(prompt_stickers) // 2], prompt_stickers[(len(prompt_stickers) // 2) : ]\n",
    "    \n",
    "        t1 = threading.Thread(target = runner, args=(p1, 'cuda:0',), daemon=False)\n",
    "        t2 = threading.Thread(target = runner, args=(p2, 'cuda:1',), daemon=False)\n",
    "        t1.start()\n",
    "        t2.start()\n",
    "        t1.join()\n",
    "        t2.join()\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-16T15:41:41.688711Z",
     "iopub.execute_input": "2024-02-16T15:41:41.689009Z",
     "iopub.status.idle": "2024-02-16T15:41:41.707096Z",
     "shell.execute_reply.started": "2024-02-16T15:41:41.688983Z",
     "shell.execute_reply": "2024-02-16T15:41:41.705971Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "result = []\n",
    "\n",
    "main(prompts)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-16T15:41:41.708376Z",
     "iopub.execute_input": "2024-02-16T15:41:41.708761Z",
     "iopub.status.idle": "2024-02-16T16:04:24.015162Z",
     "shell.execute_reply.started": "2024-02-16T15:41:41.708690Z",
     "shell.execute_reply": "2024-02-16T16:04:24.014098Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!mkdir imgs"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-16T15:33:39.638714Z",
     "iopub.status.idle": "2024-02-16T15:33:39.639021Z",
     "shell.execute_reply.started": "2024-02-16T15:33:39.638865Z",
     "shell.execute_reply": "2024-02-16T15:33:39.638879Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def dump_sticker_info(info):\n",
    "    prompt_sticker, image_sticker, image_sticker_mixed, \\\n",
    "        prompt_photo, image_photo, rnd_seed, image_photo_caption = info\n",
    "\n",
    "    sticker_record = {\n",
    "        \"prompt_sticker\": prompt_sticker,\n",
    "        \"caption\": image_photo_caption,\n",
    "        \"image_photo_name\": f\"{prompt_photo}_{rnd_seed}.png\",\n",
    "        \"image_sticker_name\": f\"{prompt_sticker}_{rnd_seed}.png\",\n",
    "        \"image_sticker_mixed_name\": f\"mixed_{prompt_sticker}_{rnd_seed}.png\"\n",
    "    }\n",
    "\n",
    "    db.child(\"prompts_generated\").push(sticker_record)\n",
    "\n",
    "    image_photo.save(os.path.join(\"imgs\", sticker_record[\"image_photo_name\"]))\n",
    "    image_sticker.save(os.path.join(\"imgs\", sticker_record[\"image_sticker_name\"]))\n",
    "    image_sticker_mixed.save(os.path.join(\"imgs\", sticker_record[\"image_sticker_mixed_name\"]))\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-16T15:33:39.640117Z",
     "iopub.status.idle": "2024-02-16T15:33:39.640469Z",
     "shell.execute_reply.started": "2024-02-16T15:33:39.640304Z",
     "shell.execute_reply": "2024-02-16T15:33:39.640320Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for info in result:\n",
    "    dump_sticker_info(info)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!zip -r imgs_result.zip imgs > /dev/null"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-16T15:33:39.641624Z",
     "iopub.status.idle": "2024-02-16T15:33:39.641936Z",
     "shell.execute_reply.started": "2024-02-16T15:33:39.641780Z",
     "shell.execute_reply": "2024-02-16T15:33:39.641794Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "show_res = True\n",
    "N_display = 10\n",
    "\n",
    "if show_res:\n",
    "    for idx, item in enumerate(result[:N_display]):\n",
    "        prompt_sticker,image_sticker1,image_sticker2, prompt,image,rnd_seed, img_cap = item\n",
    "        \n",
    "        fig, axs = plt.subplots(1, 3, figsize=(20*3, 10*3))\n",
    "\n",
    "        axs[0].imshow(image)\n",
    "        axs[0].set_title(prompt)\n",
    "        axs[0].axis('off') \n",
    "\n",
    "        axs[1].imshow(image_sticker1)\n",
    "        axs[1].set_title(prompt_sticker)\n",
    "        axs[1].axis('off')\n",
    "        \n",
    "        axs[2].imshow(image_sticker2)\n",
    "        axs[2].set_title(img_cap)\n",
    "        axs[2].axis('off')\n",
    "\n",
    "\n",
    "        plt.show()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-16T16:07:19.827863Z",
     "iopub.execute_input": "2024-02-16T16:07:19.828900Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
