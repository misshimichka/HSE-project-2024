{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30636,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers compel accelerate gdown diffusers pyrebase4 -U > /dev/null\n!gdown 1IohKG23i468616bPHBkDHiBnZvmPW3m5 > /dev/null #нужный csv с новыми промптами, которых нет в базе данных\n!gdown 1pF1u8mekNs_z_KvFIJRTdqhlFHm1lp5n > /dev/null","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-16T15:32:41.455472Z","iopub.execute_input":"2024-02-16T15:32:41.455770Z","iopub.status.idle":"2024-02-16T15:33:20.049883Z","shell.execute_reply.started":"2024-02-16T15:32:41.455744Z","shell.execute_reply":"2024-02-16T15:33:20.048889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport random\nimport sys\nimport os\nimport torch\nimport torchvision\nfrom PIL import Image, ImageDraw, ImageFont, ImageChops\nfrom scipy.spatial.qhull import QhullError\nfrom scipy import spatial\nspatial.QhullError = QhullError\nfrom tqdm.auto import tqdm\nimport io\nimport glob\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\nimport zlib\nimport requests\nfrom transformers import AutoProcessor, AutoModel\nfrom diffusers import StableDiffusionXLPipeline, UNet2DConditionModel\nimport threading\nimport os\nimport shutil\nfrom torchvision.transforms.functional import pil_to_tensor\nimport pyrebase\nfrom transformers import BlipProcessor, BlipForConditionalGeneration\nfrom compel import Compel, ReturnedEmbeddingsType\n\ncsv_path = '/kaggle/working/promptsfcsv'","metadata":{"execution":{"iopub.status.busy":"2024-02-16T15:33:20.051980Z","iopub.execute_input":"2024-02-16T15:33:20.052300Z","iopub.status.idle":"2024-02-16T15:33:38.654347Z","shell.execute_reply.started":"2024-02-16T15:33:20.052274Z","shell.execute_reply":"2024-02-16T15:33:38.653511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config_path = 'firebase_auth.json'\nassert os.path.exists(config_path)\n\nconfig = {\n  \"apiKey\": \"AIzaSyBnWywH3ZswQNyLblBohBAp__f_F2myt5M\",\n  \"authDomain\": \"datasetcollect-81ac0.firebaseapp.com\",\n  \"databaseURL\": \"https://datasetcollect-81ac0-default-rtdb.firebaseio.com\",\n  \"storageBucket\": \"datasetcollect-81ac0.appspot.com\",\n  \"ServiceAccount\":config_path,\n}\n\n\n\nfirebase = pyrebase.initialize_app(config)\ndb = firebase.database()","metadata":{"execution":{"iopub.status.busy":"2024-02-16T15:33:38.655416Z","iopub.execute_input":"2024-02-16T15:33:38.655940Z","iopub.status.idle":"2024-02-16T15:33:38.665244Z","shell.execute_reply.started":"2024-02-16T15:33:38.655913Z","shell.execute_reply":"2024-02-16T15:33:38.664224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def check_gen():\n  try:\n      val = db.get('gen_id').val()['gen_id']\n  except:\n     gen_id = db.get('gen_id').val()\n     name, val = gen_id.popitem()\n\n  if val == 0:\n    raise Exception('Wtf why gen_id != 1')\n  elif val != 1:\n    raise Exception('Wtf why gen_id != 1 or 0')\n  elif val == 1:\n    print('If u set up gen_id to 1 everything is ok')\n\n\ncheck_gen()","metadata":{"execution":{"iopub.status.busy":"2024-02-16T15:38:38.442040Z","iopub.execute_input":"2024-02-16T15:38:38.443145Z","iopub.status.idle":"2024-02-16T15:38:38.481864Z","shell.execute_reply.started":"2024-02-16T15:38:38.443107Z","shell.execute_reply":"2024-02-16T15:38:38.480936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(csv_path)\ndf['prompt'] = df['prompt'].apply(lambda x: x.strip()[:-1:])#удалили точку, тут такого быть не должно, дынные сразу должны соответствовать формату\ndf","metadata":{"execution":{"iopub.status.busy":"2024-02-16T15:38:42.974360Z","iopub.execute_input":"2024-02-16T15:38:42.975300Z","iopub.status.idle":"2024-02-16T15:38:43.019055Z","shell.execute_reply.started":"2024-02-16T15:38:42.975268Z","shell.execute_reply":"2024-02-16T15:38:43.018073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_id = \"stabilityai/stable-diffusion-xl-base-1.0\"\nunet_id = \"mhdang/dpo-sdxl-text2image-v1\"\n\npipe1 = StableDiffusionXLPipeline.from_pretrained(model_id, torch_dtype=torch.float16, variant=\"fp16\", use_safetensors=True).to(\"cuda:0\")\nunet1 = UNet2DConditionModel.from_pretrained(unet_id, subfolder=\"unet\", torch_dtype=torch.float16).to('cuda:0')\npipe1.unet = unet1\npipe1 = pipe1.to(\"cuda:0\")\n\npipe2 = StableDiffusionXLPipeline.from_pretrained(model_id, torch_dtype=torch.float16, variant=\"fp16\", use_safetensors=True).to(\"cuda:1\")\nunet2 = UNet2DConditionModel.from_pretrained(unet_id, subfolder=\"unet\", torch_dtype=torch.float16).to('cuda:1')\npipe2.unet = unet2\npipe2 = pipe2.to(\"cuda:1\")","metadata":{"execution":{"iopub.status.busy":"2024-02-16T15:38:43.157538Z","iopub.execute_input":"2024-02-16T15:38:43.158109Z","iopub.status.idle":"2024-02-16T15:41:32.960838Z","shell.execute_reply.started":"2024-02-16T15:38:43.158081Z","shell.execute_reply":"2024-02-16T15:41:32.959687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"blip_version = \"noamrot/FuseCap\"\n\nblip_processor = BlipProcessor.from_pretrained(blip_version)\nblip_model1 = BlipForConditionalGeneration.from_pretrained(blip_version).to(\"cuda:0\")\n\nblip_model2 = BlipForConditionalGeneration.from_pretrained(blip_version).to(\"cuda:1\")","metadata":{"execution":{"iopub.status.busy":"2024-02-16T15:41:32.962802Z","iopub.execute_input":"2024-02-16T15:41:32.963123Z","iopub.status.idle":"2024-02-16T15:41:41.542502Z","shell.execute_reply.started":"2024-02-16T15:41:32.963097Z","shell.execute_reply":"2024-02-16T15:41:41.541442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_caption(raw_image, device):\n    \n    inputs = blip_processor(raw_image, return_tensors=\"pt\").to(\n        device)\n    if device == 'cuda:0':\n        out = blip_model1.generate(**inputs)\n    else:\n        out = blip_model2.generate(**inputs)\n    caption = blip_processor.decode(out[0], skip_special_tokens=True)\n    return caption.strip()","metadata":{"execution":{"iopub.status.busy":"2024-02-16T15:41:41.543764Z","iopub.execute_input":"2024-02-16T15:41:41.544084Z","iopub.status.idle":"2024-02-16T15:41:41.552678Z","shell.execute_reply.started":"2024-02-16T15:41:41.544059Z","shell.execute_reply":"2024-02-16T15:41:41.551836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_compel1 = Compel(\n    tokenizer=[pipe1.tokenizer, pipe1.tokenizer_2],\n    text_encoder=[pipe1.text_encoder, pipe1.text_encoder_2],\n    returned_embeddings_type=ReturnedEmbeddingsType.PENULTIMATE_HIDDEN_STATES_NON_NORMALIZED,\n    requires_pooled=[False, True]\n)\n\nbase_compel2 = Compel(\n    tokenizer=[pipe2.tokenizer, pipe2.tokenizer_2],\n    text_encoder=[pipe2.text_encoder, pipe2.text_encoder_2],\n    returned_embeddings_type=ReturnedEmbeddingsType.PENULTIMATE_HIDDEN_STATES_NON_NORMALIZED,\n    requires_pooled=[False, True]\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-16T15:41:41.555131Z","iopub.execute_input":"2024-02-16T15:41:41.555498Z","iopub.status.idle":"2024-02-16T15:41:41.687325Z","shell.execute_reply.started":"2024-02-16T15:41:41.555465Z","shell.execute_reply":"2024-02-16T15:41:41.686390Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def gen_sticker_with_mixed_prompts(prompt_sticker, caption, generator, device, sticker_cond = 'a cartoon sticker', x1=1.0, x2=0.55,x3=1.0):\n    prompt = f'\"{prompt_sticker}\", \"{caption}\", \"{sticker_cond}\").blend({x1}, {x2}, {x3})'\n    \n    if device == 'cuda:0':\n    \n        base_positive_prompt_embeds, base_positive_prompt_pooled = base_compel1(prompt)\n        base_negative_prompt_embeds, base_negative_prompt_pooled = base_compel1('low-quality')\n        base_positive_prompt_embeds, base_negative_prompt_embeds = base_compel1.pad_conditioning_tensors_to_same_length([\n            base_positive_prompt_embeds, base_negative_prompt_embeds\n        ])\n\n        image_sticker_new = pipe1(prompt_embeds=base_positive_prompt_embeds,\n            pooled_prompt_embeds=base_positive_prompt_pooled,\n            negative_prompt_embeds=base_negative_prompt_embeds,\n            negative_pooled_prompt_embeds=base_negative_prompt_pooled,\n            output_type=\"pil\", guidance_scale=5, generator=generator).images[0]\n    else:\n            \n        base_positive_prompt_embeds, base_positive_prompt_pooled = base_compel2(prompt)\n        base_negative_prompt_embeds, base_negative_prompt_pooled = base_compel2('low-quality')\n        base_positive_prompt_embeds, base_negative_prompt_embeds = base_compel2.pad_conditioning_tensors_to_same_length([\n            base_positive_prompt_embeds, base_negative_prompt_embeds\n        ])\n\n        image_sticker_new = pipe2(prompt_embeds=base_positive_prompt_embeds,\n            pooled_prompt_embeds=base_positive_prompt_pooled,\n            negative_prompt_embeds=base_negative_prompt_embeds,\n            negative_pooled_prompt_embeds=base_negative_prompt_pooled,\n            output_type=\"pil\", guidance_scale=5, generator=generator).images[0]\n        \n        \n    return image_sticker_new\n\n\ndef generate_seed_from_prompt(prompt):\n    return zlib.adler32(prompt.encode())\n\ndef get_rand_gen(prompt, device):\n    rnd_seed = generate_seed_from_prompt(prompt)\n    return torch.Generator(device).manual_seed(rnd_seed), rnd_seed\n\ndef get_pair_data(prompt_sticker, device):\n    prompt = prompt_sticker.replace('A sticker', 'A photo', 1)\n    prompt += ', 8k, fullHD, realistic photography.'\n    prompt_sticker += ', cartoon style.'\n    generator, rnd_seed = get_rand_gen(prompt, device)\n    \n    if device == 'cuda:0':\n        image = pipe1(prompt, guidance_scale=5, generator=generator).images[0]\n        img_cap = generate_caption(image, device)\n        image_sticker1 = pipe1(prompt_sticker, guidance_scale=5, generator=generator).images[0]\n    else:\n        image = pipe2(prompt, guidance_scale=5, generator=generator).images[0]\n        img_cap = generate_caption(image, device)\n        image_sticker1 = pipe2(prompt_sticker, guidance_scale=5, generator=generator).images[0]\n        \n    image_sticker2 = gen_sticker_with_mixed_prompts(prompt_sticker, img_cap, generator, device)\n\n    return (prompt_sticker,image_sticker1,image_sticker2, prompt,image,rnd_seed, img_cap)\n\n\ndef runner(prompt_stickers, device):\n    global max_results, result\n    \n    count = 0\n    for prompt_sticker in tqdm(prompt_stickers):\n        data = get_pair_data(prompt_sticker, device)\n        count += 1\n        result.append(data)\n                \n        if count == max_results // 2:\n            break\n    \ndef main(prompt_stickers):\n    try:\n        p1, p2 = prompt_stickers[:len(prompt_stickers) // 2], prompt_stickers[(len(prompt_stickers) // 2) : ]\n    \n        t1 = threading.Thread(target = runner, args=(p1, 'cuda:0',), daemon=False)\n        t2 = threading.Thread(target = runner, args=(p2, 'cuda:1',), daemon=False)\n        t1.start()\n        t2.start()\n        t1.join()\n        t2.join()\n    except KeyboardInterrupt:\n        pass\n    ","metadata":{"execution":{"iopub.status.busy":"2024-02-16T15:41:41.688711Z","iopub.execute_input":"2024-02-16T15:41:41.689009Z","iopub.status.idle":"2024-02-16T15:41:41.707096Z","shell.execute_reply.started":"2024-02-16T15:41:41.688983Z","shell.execute_reply":"2024-02-16T15:41:41.705971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_results = 20 #пусть будет четное, мне лень писать нормальный код\n\nresult = []\nprompts = df['prompt']\nmain(prompts)","metadata":{"execution":{"iopub.status.busy":"2024-02-16T15:41:41.708376Z","iopub.execute_input":"2024-02-16T15:41:41.708761Z","iopub.status.idle":"2024-02-16T16:04:24.015162Z","shell.execute_reply.started":"2024-02-16T15:41:41.708690Z","shell.execute_reply":"2024-02-16T16:04:24.014098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir imgs","metadata":{"execution":{"iopub.status.busy":"2024-02-16T15:33:39.638714Z","iopub.status.idle":"2024-02-16T15:33:39.639021Z","shell.execute_reply.started":"2024-02-16T15:33:39.638865Z","shell.execute_reply":"2024-02-16T15:33:39.638879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"table_to_upd = 'table1'\n\nfor prompt_sticker,image_sticker1,image_sticker2, prompt,image,rnd_seed, img_cap in result:\n    data = {'prompt_sticker':prompt_sticker,  'image':f'{prompt}_{rnd_seed}.png', 'caption':img_cap}\n    \n    data['image_sticker1'] =  f'1_{prompt_sticker}_{rnd_seed}.png'\n    image_sticker1.save(os.path.join('imgs', data['image_sticker1']))\n        \n    data['image_sticker2'] =  f'2_{prompt_sticker}_{rnd_seed}.png'\n    image_sticker2.save(os.path.join('imgs', data['image_sticker2']))\n    \n    \n    db.child(table_to_upd).push(data)\n    image.save(os.path.join('imgs', data['image']))","metadata":{"execution":{"iopub.status.busy":"2024-02-16T15:33:39.640117Z","iopub.status.idle":"2024-02-16T15:33:39.640469Z","shell.execute_reply.started":"2024-02-16T15:33:39.640304Z","shell.execute_reply":"2024-02-16T15:33:39.640320Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!zip -r imgs_result.zip imgs > /dev/null","metadata":{"execution":{"iopub.status.busy":"2024-02-16T15:33:39.641624Z","iopub.status.idle":"2024-02-16T15:33:39.641936Z","shell.execute_reply.started":"2024-02-16T15:33:39.641780Z","shell.execute_reply":"2024-02-16T15:33:39.641794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_res = True\nN_display = 10\n\nif show_res:\n    for idx, item in enumerate(result[:N_display]):\n        prompt_sticker,image_sticker1,image_sticker2, prompt,image,rnd_seed, img_cap = item\n        \n        fig, axs = plt.subplots(1, 3, figsize=(20*3, 10*3))\n\n        axs[0].imshow(image)\n        axs[0].set_title(prompt)\n        axs[0].axis('off') \n\n        axs[1].imshow(image_sticker1)\n        axs[1].set_title(prompt_sticker)\n        axs[1].axis('off')\n        \n        axs[2].imshow(image_sticker2)\n        axs[2].set_title(img_cap)\n        axs[2].axis('off')\n\n\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-16T16:07:19.827863Z","iopub.execute_input":"2024-02-16T16:07:19.828900Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#db.child(\"gen_id\").set(0) если вы вообще пока больше генерить не будите, а не просто конкретно на этом ноутбуке закончили генерацию","metadata":{"execution":{"iopub.status.busy":"2024-02-16T15:33:39.644752Z","iopub.status.idle":"2024-02-16T15:33:39.645064Z","shell.execute_reply.started":"2024-02-16T15:33:39.644901Z","shell.execute_reply":"2024-02-16T15:33:39.644915Z"},"trusted":true},"execution_count":null,"outputs":[]}]}
