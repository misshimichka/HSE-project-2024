{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "6f67959b",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2024-03-10T04:57:03.695686Z",
          "iopub.status.busy": "2024-03-10T04:57:03.694855Z",
          "iopub.status.idle": "2024-03-10T04:57:33.685093Z",
          "shell.execute_reply": "2024-03-10T04:57:33.684019Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "papermill": {
          "duration": 29.997835,
          "end_time": "2024-03-10T04:57:33.687538",
          "exception": false,
          "start_time": "2024-03-10T04:57:03.689703",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "6f67959b",
        "outputId": "f8e8c489-9013-4bd8-d7ee-de930946ab43"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Мы разбили этот ноутбук на 2 ноутбука, в первом считаются одни метрики,\\nв следущем досчитывается другая метрика: face_emb_sim_between_real_img_and_generated_sticker'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "'''Мы разбили этот ноутбук на 2 ноутбука, в первом считаются одни метрики,\n",
        "в следущем досчитывается другая метрика: face_emb_sim_between_real_img_and_generated_sticker'''\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Первый ноутбук"
      ],
      "metadata": {
        "id": "xs6o-LGLfcIQ"
      },
      "id": "xs6o-LGLfcIQ",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers accelerate gdown  pyiqa  -U"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWe_cEa4ffou",
        "outputId": "0cd7ac3f-ff03-4915-a16a-51d227b2b43a"
      },
      "id": "BWe_cEa4ffou",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.2)\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.30.0-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.4/302.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.1.0)\n",
            "Collecting pyiqa\n",
            "  Downloading pyiqa-0.1.11-py3-none-any.whl (247 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m248.0/248.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
            "Collecting addict (from pyiqa)\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from pyiqa) (0.18.3)\n",
            "Collecting lmdb (from pyiqa)\n",
            "  Downloading lmdb-1.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (299 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from pyiqa) (4.8.0.76)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from pyiqa) (2.0.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from pyiqa) (9.4.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from pyiqa) (0.19.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pyiqa) (1.11.4)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from pyiqa) (2.15.2)\n",
            "Collecting timm (from pyiqa)\n",
            "  Downloading timm-0.9.16-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision>=0.13 in /usr/local/lib/python3.10/dist-packages (from pyiqa) (0.17.1+cu121)\n",
            "Collecting yapf (from pyiqa)\n",
            "  Downloading yapf-0.40.2-py3-none-any.whl (254 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.7/254.7 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops (from pyiqa)\n",
            "  Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: imgaug in /usr/local/lib/python3.10/dist-packages (from pyiqa) (0.4.0)\n",
            "Collecting openai-clip (from pyiqa)\n",
            "  Downloading openai-clip-1.0.1.tar.gz (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66055501",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-10T04:57:33.747793Z",
          "iopub.status.busy": "2024-03-10T04:57:33.747558Z",
          "iopub.status.idle": "2024-03-10T04:57:53.245550Z",
          "shell.execute_reply": "2024-03-10T04:57:53.244743Z"
        },
        "papermill": {
          "duration": 19.508662,
          "end_time": "2024-03-10T04:57:53.247936",
          "exception": false,
          "start_time": "2024-03-10T04:57:33.739274",
          "status": "completed"
        },
        "tags": [],
        "id": "66055501"
      },
      "outputs": [],
      "source": [
        "from scipy.spatial.qhull import QhullError\n",
        "from scipy import spatial\n",
        "spatial.QhullError = QhullError\n",
        "from tqdm.auto import tqdm\n",
        "import io\n",
        "import glob\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import pyiqa\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import zlib\n",
        "import requests\n",
        "from transformers import AutoProcessor, AutoModel\n",
        "import threading\n",
        "import os\n",
        "import shutil\n",
        "import pyiqa\n",
        "from torchvision.transforms.functional import pil_to_tensor\n",
        "import cv2\n",
        "from transformers import AutoImageProcessor\n",
        "import numpy as np\n",
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torchvision\n",
        "from PIL import Image, ImageDraw, ImageFont, ImageChops\n",
        "device = 'cuda:0'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2974712b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-10T04:57:53.265365Z",
          "iopub.status.busy": "2024-03-10T04:57:53.264539Z",
          "iopub.status.idle": "2024-03-10T04:58:13.991459Z",
          "shell.execute_reply": "2024-03-10T04:58:13.990627Z"
        },
        "papermill": {
          "duration": 20.737787,
          "end_time": "2024-03-10T04:58:13.993721",
          "exception": false,
          "start_time": "2024-03-10T04:57:53.255934",
          "status": "completed"
        },
        "tags": [],
        "id": "2974712b"
      },
      "outputs": [],
      "source": [
        "clip_model_id = 'google/siglip-so400m-patch14-384'\n",
        "iqa_model_id = 'topiq_iaa'\n",
        "device = 'cuda:0'\n",
        "SIZE = 512\n",
        "\n",
        "\n",
        "aes_metric = pyiqa.create_metric(iqa_model_id).net.to('cuda:0')\n",
        "\n",
        "clip_model = AutoModel.from_pretrained(clip_model_id).to('cuda:0')\n",
        "processor = AutoProcessor.from_pretrained(clip_model_id)\n",
        "\n",
        "\n",
        "IMAGENET_DEFAULT_MEAN = (0.485, 0.456, 0.406)\n",
        "IMAGENET_DEFAULT_STD = (0.229, 0.224, 0.225)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "transforms.ToTensor(),\n",
        "transforms.Normalize(IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd1c7209",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-10T04:58:14.017908Z",
          "iopub.status.busy": "2024-03-10T04:58:14.017516Z",
          "iopub.status.idle": "2024-03-10T04:58:14.040299Z",
          "shell.execute_reply": "2024-03-10T04:58:14.039360Z"
        },
        "papermill": {
          "duration": 0.037216,
          "end_time": "2024-03-10T04:58:14.042304",
          "exception": false,
          "start_time": "2024-03-10T04:58:14.005088",
          "status": "completed"
        },
        "tags": [],
        "id": "dd1c7209"
      },
      "outputs": [],
      "source": [
        "def cosine_sim(x, y):\n",
        "    return torch.nn.functional.cosine_similarity(x, y)\n",
        "\n",
        "def aesthetic_score(x, device):\n",
        "    x = transform(x).to(device)\n",
        "    return aes_metric(x) / 10\n",
        "\n",
        "\n",
        "def get_faces_score(img_sticker,img_orig, device='cuda:0'):\n",
        "\n",
        "    img_orig_preprocessed = processor(images=img_orig, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    img_sticker_preprocessed = processor(images=img_sticker, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    prompt_is_sticker_preprocessed = processor(text='a sticker.', return_tensors=\"pt\", padding=\"max_length\").to(device)\n",
        "    prompt_has_face_preprocessed = processor(text='a face.', return_tensors=\"pt\", padding=\"max_length\").to(device)\n",
        "\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        img_orig_emb = clip_model.get_image_features(**img_orig_preprocessed).to(device)\n",
        "        img_sticker_emb = clip_model.get_image_features(**img_sticker_preprocessed).to(device)\n",
        "\n",
        "        prompt_is_sticker_emb = clip_model.get_text_features(**prompt_is_sticker_preprocessed).to(device)\n",
        "        prompt_has_face_emb = clip_model.get_text_features(**prompt_has_face_preprocessed).to(device)\n",
        "\n",
        "\n",
        "\n",
        "    x1 = cosine_sim(img_orig_emb, img_sticker_emb).cpu().detach().numpy()[0]\n",
        "    x3 = aesthetic_score(img_sticker, device).cpu().detach().numpy()[0][0]\n",
        "    x4 = cosine_sim(img_sticker_emb, prompt_is_sticker_emb).cpu().detach().numpy()[0]\n",
        "    x6 = aesthetic_score(img_orig, device).cpu().detach().numpy()[0][0]\n",
        "    x8 = cosine_sim(img_sticker_emb, prompt_has_face_emb).cpu().detach().numpy()[0]\n",
        "\n",
        "\n",
        "    data = {}\n",
        "    data['sim_between_real_img_and_generated_sticker'] = x1\n",
        "    data['aes_img'] = x6\n",
        "\n",
        "    data['sim_between_generated_sticker_and_is_sticker_prompt'] = x4\n",
        "    data['sim_between_generated_sticker_and_has_face_prompt'] = x8\n",
        "    data['aes_sticker'] = x3\n",
        "    return data\n",
        "\n",
        "\n",
        "\n",
        "def parse_faces(paths):\n",
        "    colnames = ['img', 'sticker',\n",
        "       'sim_between_real_img_and_generated_sticker', 'aes_img',\n",
        "       'sim_between_generated_sticker_and_is_sticker_prompt',\n",
        "       'sim_between_generated_sticker_and_has_face_prompt', 'aes_sticker']\n",
        "    data = {i:[] for i in colnames}\n",
        "    for sticker_path, orig_path in tqdm(paths):\n",
        "        data['img'].append(orig_path)\n",
        "        data['sticker'].append(sticker_path)\n",
        "        img_sticker = Image.open(sticker_path)\n",
        "        img_orig = Image.open(orig_path)\n",
        "        metrics = get_faces_score(img_sticker, img_orig)\n",
        "        for i in colnames:\n",
        "            if i in ['img', 'sticker']:\n",
        "                continue\n",
        "            data[i].append(metrics[i])\n",
        "    return pd.DataFrame(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59482aa0",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-10T04:58:14.064518Z",
          "iopub.status.busy": "2024-03-10T04:58:14.064021Z",
          "iopub.status.idle": "2024-03-10T04:58:15.431714Z",
          "shell.execute_reply": "2024-03-10T04:58:15.430835Z"
        },
        "papermill": {
          "duration": 1.380755,
          "end_time": "2024-03-10T04:58:15.433702",
          "exception": false,
          "start_time": "2024-03-10T04:58:14.052947",
          "status": "completed"
        },
        "tags": [],
        "id": "59482aa0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "\n",
        "paths = []\n",
        "for q in range(8):\n",
        "    directory = f'/kaggle/input/fake-faces-dataset/fake_stickers_{q}/fake_stickers'\n",
        "    for i in os.listdir(directory):\n",
        "        if 'orig' not in i:\n",
        "            paths.append(os.path.join(directory, i))\n",
        "\n",
        "paths.sort(key=lambda x: int(x.split('/')[-1].split('_')[1]))\n",
        "\n",
        "\n",
        "final_paths = []\n",
        "\n",
        "for path in paths:\n",
        "    idx = path.split('/')[-1].split('_')[1]\n",
        "    orig_path = path.replace(f'{idx}_sticker', f'{idx}_orig')\n",
        "    final_paths.append([path, orig_path])\n",
        "\n",
        "print(final_paths[0])\n",
        "print(final_paths[-1])\n",
        "len(final_paths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5ee9a5c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-10T04:58:15.456683Z",
          "iopub.status.busy": "2024-03-10T04:58:15.456388Z",
          "iopub.status.idle": "2024-03-10T05:49:31.534016Z",
          "shell.execute_reply": "2024-03-10T05:49:31.532679Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "papermill": {
          "duration": 3076.092306,
          "end_time": "2024-03-10T05:49:31.536778",
          "exception": false,
          "start_time": "2024-03-10T04:58:15.444472",
          "status": "completed"
        },
        "tags": [],
        "id": "d5ee9a5c"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "result = parse_faces(final_paths)\n",
        "result.to_csv('result.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Следующий ноутбук"
      ],
      "metadata": {
        "id": "ew9c7WgIe8sG"
      },
      "id": "ew9c7WgIe8sG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown deepface -U\n",
        "!gdown 1G93SzaMuTDDhK3ilklG4nbsxvDxazfcp"
      ],
      "metadata": {
        "id": "TRNIBlSIfCtM"
      },
      "id": "TRNIBlSIfCtM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tqdm.auto import tqdm\n",
        "import pandas as pd\n",
        "from deepface import DeepFace\n",
        "\n",
        "\n",
        "paths = []\n",
        "for q in range(8):\n",
        "    directory = f'/kaggle/input/fake-faces-dataset/fake_stickers_{q}/fake_stickers'\n",
        "    for i in os.listdir(directory):\n",
        "        if 'orig' not in i:\n",
        "            paths.append(os.path.join(directory, i))\n",
        "\n",
        "paths.sort(key=lambda x: int(x.split('/')[-1].split('_')[1]))\n",
        "\n",
        "\n",
        "final_paths = []\n",
        "\n",
        "for path in paths:\n",
        "    idx = path.split('/')[-1].split('_')[1]\n",
        "    orig_path = path.replace(f'{idx}_sticker', f'{idx}_orig')\n",
        "    final_paths.append([path, orig_path])\n",
        "\n",
        "print(final_paths[0])\n",
        "print(final_paths[-1])\n",
        "len(final_paths)"
      ],
      "metadata": {
        "id": "Hw-321UqfGFW"
      },
      "id": "Hw-321UqfGFW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/kaggle/working/result_fakeds.csv')"
      ],
      "metadata": {
        "id": "aIp2a4wNfIHC"
      },
      "id": "aIp2a4wNfIHC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "colnames = ['img', 'sticker', 'face_emb_sim_between_real_img_and_generated_sticker',\n",
        "       'sim_between_real_img_and_generated_sticker', 'aes_img',\n",
        "       'sim_between_generated_sticker_and_is_sticker_prompt',\n",
        "       'sim_between_generated_sticker_and_has_face_prompt', 'aes_sticker']\n",
        "\n",
        "data_x = {i:[] for i in colnames}\n",
        "\n",
        "\n",
        "for idx, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
        "    for name in colnames:\n",
        "        if name == 'face_emb_sim_between_real_img_and_generated_sticker':\n",
        "            continue\n",
        "        data_x[name].append(row[name])\n",
        "\n",
        "    try:\n",
        "        out = DeepFace.verify(img1_path = row['img'], img2_path = row['sticker'], detector_backend='retinaface')\n",
        "        dist = out['distance']\n",
        "    except ValueError:\n",
        "        dist = 1\n",
        "\n",
        "    data_x['face_emb_sim_between_real_img_and_generated_sticker'].append(1 - dist)"
      ],
      "metadata": {
        "id": "ukJ-sBVGfLTv"
      },
      "id": "ukJ-sBVGfLTv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(data_x)\n",
        "df"
      ],
      "metadata": {
        "id": "sq2H6vBZfOm6"
      },
      "id": "sq2H6vBZfOm6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('fake-faces-dataset_cleaned.csv', index=False)"
      ],
      "metadata": {
        "id": "cDyr9pXdfQ6m"
      },
      "id": "cDyr9pXdfQ6m",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 4569852,
          "sourceId": 7803981,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30664,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 3154.592888,
      "end_time": "2024-03-10T05:49:35.428713",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2024-03-10T04:57:00.835825",
      "version": "2.5.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}