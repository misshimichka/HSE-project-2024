{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install openai","metadata":{"execution":{"iopub.status.busy":"2024-03-03T15:18:57.385551Z","iopub.execute_input":"2024-03-03T15:18:57.385780Z","iopub.status.idle":"2024-03-03T15:19:08.550055Z","shell.execute_reply.started":"2024-03-03T15:18:57.385758Z","shell.execute_reply":"2024-03-03T15:19:08.549352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from openai import OpenAI\n\n# Currently invalid\nAPI_KEY = \"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\"\n\nclient = OpenAI(api_key=API_KEY)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-03T15:19:52.962755Z","iopub.execute_input":"2024-03-03T15:19:52.963103Z","iopub.status.idle":"2024-03-03T15:19:53.665453Z","shell.execute_reply.started":"2024-03-03T15:19:52.963080Z","shell.execute_reply":"2024-03-03T15:19:53.664867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"content = \"\"\"\n    I want to build a dataset for my project, that will consist of various sticker prompts about food.\n    Prompts have to be related to various food.\n    Give me 100 prompts which follows this format: \"A sticker of {} .\"\n    Add text instead of {}.\n    Try really hard to use different food.\n    Pay attention so the prompts become very unique and different.\n    It is extremely important for prompts to be different and not to be the same.\n    Add as much details as you can to make it look unique.\n    Just write 100 prompts, don't output any other text.\n    Preferred length of prompt is around 14 words. Write 14 words per prompt.\n    \"\"\"\n\nmessage = {\n    \"role\": \"user\",\n    \"content\": content\n}\n\ncnt_requests = 600\n\nresponses = []\n\nmessages = [{\n    \"role\": \"user\",\n    \"content\": content\n}]\n\nfor i in range(cnt_requests):\n    print(\"Making request number: \", i + 1)\n    \n#     messages.append({\n#         \"role\": \"user\",\n#         \"content\": content\n#     })\n    \n    completion = client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        messages=messages)\n    assistant_response = completion.choices[0].message.content\n        \n    responses.append(assistant_response)\n    \n#     messages.append({\n#         \"role\": \"assistant\",\n#         \"content\": assistant_response\n#     })","metadata":{"execution":{"iopub.status.busy":"2024-03-03T15:20:46.746225Z","iopub.execute_input":"2024-03-03T15:20:46.746515Z","iopub.status.idle":"2024-03-03T15:22:03.185615Z","shell.execute_reply.started":"2024-03-03T15:20:46.746491Z","shell.execute_reply":"2024-03-03T15:22:03.184846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prompts = []\n\nfor response in responses:\n    prompts.extend(response.split(\"\\n\"))\n\nfor i in range(len(prompts)):\n    prompt_beginning_index = prompts[i].lower().find(\"a\")\n    prompts[i] = prompts[i][prompt_beginning_index:].capitalize()\n    \nprint(prompts[:10])","metadata":{"execution":{"iopub.status.busy":"2024-03-03T15:23:11.533216Z","iopub.execute_input":"2024-03-03T15:23:11.533512Z","iopub.status.idle":"2024-03-03T15:23:11.539633Z","shell.execute_reply.started":"2024-03-03T15:23:11.533489Z","shell.execute_reply":"2024-03-03T15:23:11.538857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prompts_unfiltered = prompts.copy()","metadata":{"execution":{"iopub.status.busy":"2024-03-02T22:04:48.876895Z","iopub.execute_input":"2024-03-02T22:04:48.877355Z","iopub.status.idle":"2024-03-02T22:04:48.883607Z","shell.execute_reply.started":"2024-03-02T22:04:48.877314Z","shell.execute_reply":"2024-03-02T22:04:48.882184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prompts = list(filter(lambda x: len(x) >= 20, prompts_unfiltered))","metadata":{"execution":{"iopub.status.busy":"2024-03-02T22:04:51.696528Z","iopub.execute_input":"2024-03-02T22:04:51.697171Z","iopub.status.idle":"2024-03-02T22:04:51.703926Z","shell.execute_reply.started":"2024-03-02T22:04:51.697125Z","shell.execute_reply":"2024-03-02T22:04:51.702632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir collected-prompts","metadata":{"execution":{"iopub.status.busy":"2024-03-02T16:46:01.549841Z","iopub.execute_input":"2024-03-02T16:46:01.550639Z","iopub.status.idle":"2024-03-02T16:46:02.568527Z","shell.execute_reply.started":"2024-03-02T16:46:01.550600Z","shell.execute_reply":"2024-03-02T16:46:02.567217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dump_prompts(generated_prompts, batch_id):\n    \n    def get_prompts_batch_name(batch_id):\n        return \"/kaggle/working/collected-prompts/prompts-batch-\" + str(batch_id) + \".txt\"\n    \n    with open(get_prompts_batch_name(batch_id), mode=\"w\", encoding=\"UTF-8\") as prompts_batch_file:\n        for prompt in generated_prompts:\n            prompts_batch_file.write(prompt + \"\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-03-02T16:46:02.570591Z","iopub.execute_input":"2024-03-02T16:46:02.571487Z","iopub.status.idle":"2024-03-02T16:46:02.579290Z","shell.execute_reply.started":"2024-03-02T16:46:02.571437Z","shell.execute_reply":"2024-03-02T16:46:02.577799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_id = 14\n\ndump_prompts(prompts, batch_id)","metadata":{"execution":{"iopub.status.busy":"2024-03-02T16:46:02.582553Z","iopub.execute_input":"2024-03-02T16:46:02.582932Z","iopub.status.idle":"2024-03-02T16:46:02.593764Z","shell.execute_reply.started":"2024-03-02T16:46:02.582902Z","shell.execute_reply":"2024-03-02T16:46:02.592612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}