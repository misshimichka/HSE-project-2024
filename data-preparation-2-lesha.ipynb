{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30636,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers accelerate gdown diffusers pyiqa pyrebase4 -U\n!gdown 1IohKG23i468616bPHBkDHiBnZvmPW3m5 #нужный csv с новыми промптами, которых нет в базе данных\n!gdown 1pF1u8mekNs_z_KvFIJRTdqhlFHm1lp5n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-23T15:18:35.623638Z","iopub.execute_input":"2024-01-23T15:18:35.624394Z","iopub.status.idle":"2024-01-23T15:19:11.730111Z","shell.execute_reply.started":"2024-01-23T15:18:35.624358Z","shell.execute_reply":"2024-01-23T15:19:11.729000Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy import spatial\nfrom scipy.spatial.qhull import QhullError\n\nimport io\nimport os\nimport glob\nimport zlib\nimport shutil\nimport requests\nimport threading\nfrom tqdm.auto import tqdm\n\nimport pandas as pd\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\nimport pyiqa\n\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\n\nimport torchvision.transforms as transforms\nfrom torchvision.transforms.functional import pil_to_tensor\n\nfrom transformers import AutoProcessor, AutoModel\n\nfrom diffusers import StableDiffusionXLPipeline, UNet2DConditionModel\n\nimport pyrebase\n\n\nspatial.QhullError = QhullError\ncsv_path = '/kaggle/working/prompts.csv'","metadata":{"execution":{"iopub.status.busy":"2024-01-23T15:19:51.444333Z","iopub.execute_input":"2024-01-23T15:19:51.445447Z","iopub.status.idle":"2024-01-23T15:19:51.453041Z","shell.execute_reply.started":"2024-01-23T15:19:51.445413Z","shell.execute_reply":"2024-01-23T15:19:51.451912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config_path = 'firebase_auth.json'\nassert os.path.exists(config_path)\n\nconfig = {\n  \"apiKey\": \"AIzaSyBnWywH3ZswQNyLblBohBAp__f_F2myt5M\",\n  \"authDomain\": \"datasetcollect-81ac0.firebaseapp.com\",\n  \"databaseURL\": \"https://datasetcollect-81ac0-default-rtdb.firebaseio.com\",\n  \"storageBucket\": \"datasetcollect-81ac0.appspot.com\",\n  \"ServiceAccount\":config_path,\n}\n\nfirebase = pyrebase.initialize_app(config)\ndb = firebase.database()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def check_gen():\n    gen_id = db.get('gen_id').val()\n    if not gen_id:\n        raise Exception('Unexpected behaviour, gen_id has to be defined, contact @round_tensor')\n    name, val = gen_id.popitem()\n    if val == 0:\n        raise Exception('Wtf why gen_id != 1')\n    elif val != 1:\n        raise Exception('Wtf why gen_id != 1 or 0')\n    elif val == 1:\n        print('If u set up gen_id to 1 everything is ok')\n\n\ncheck_gen()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"aes_metric1 = pyiqa.create_metric(\"topiq_iaa\").net.to('cuda:0')\naes_metric2 = pyiqa.create_metric(\"topiq_iaa\").net.to('cuda:1')","metadata":{"execution":{"iopub.status.busy":"2024-01-23T15:19:51.455124Z","iopub.execute_input":"2024-01-23T15:19:51.455523Z","iopub.status.idle":"2024-01-23T15:19:59.441904Z","shell.execute_reply.started":"2024-01-23T15:19:51.455497Z","shell.execute_reply":"2024-01-23T15:19:59.441083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clip_model1 = AutoModel.from_pretrained(\"google/siglip-base-patch16-224\").to('cuda:0')\nclip_model2 = AutoModel.from_pretrained(\"google/siglip-base-patch16-224\").to('cuda:1')\n\nprocessor = AutoProcessor.from_pretrained(\"google/siglip-base-patch16-224\")","metadata":{"execution":{"iopub.status.busy":"2024-01-23T15:19:59.443487Z","iopub.execute_input":"2024-01-23T15:19:59.443867Z","iopub.status.idle":"2024-01-23T15:20:06.865202Z","shell.execute_reply.started":"2024-01-23T15:19:59.443831Z","shell.execute_reply":"2024-01-23T15:20:06.864359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(csv_path)","metadata":{"execution":{"iopub.status.busy":"2024-01-23T15:20:06.867387Z","iopub.execute_input":"2024-01-23T15:20:06.867710Z","iopub.status.idle":"2024-01-23T15:20:06.900478Z","shell.execute_reply.started":"2024-01-23T15:20:06.867682Z","shell.execute_reply":"2024-01-23T15:20:06.899539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_id = \"stabilityai/stable-diffusion-xl-base-1.0\"\nunet_id = \"mhdang/dpo-sdxl-text2image-v1\"\n\npipe1 = StableDiffusionXLPipeline.from_pretrained(model_id, torch_dtype=torch.float16, variant=\"fp16\", use_safetensors=True).to(\"cuda:0\")\nunet1 = UNet2DConditionModel.from_pretrained(unet_id, subfolder=\"unet\", torch_dtype=torch.float16).to('cuda:0')\npipe1.unet = unet1\npipe1 = pipe1.to(\"cuda:0\")\n\npipe2 = StableDiffusionXLPipeline.from_pretrained(model_id, torch_dtype=torch.float16, variant=\"fp16\", use_safetensors=True).to(\"cuda:1\")\nunet2 = UNet2DConditionModel.from_pretrained(unet_id, subfolder=\"unet\", torch_dtype=torch.float16).to('cuda:1')\npipe2.unet = unet2\npipe2 = pipe2.to(\"cuda:1\")","metadata":{"execution":{"iopub.status.busy":"2024-01-23T15:20:06.901568Z","iopub.execute_input":"2024-01-23T15:20:06.901817Z","iopub.status.idle":"2024-01-23T15:23:25.462028Z","shell.execute_reply.started":"2024-01-23T15:20:06.901795Z","shell.execute_reply":"2024-01-23T15:23:25.461124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGENET_DEFAULT_MEAN = (0.485, 0.456, 0.406)\nIMAGENET_DEFAULT_STD = (0.229, 0.224, 0.225)\n\ntransform = transforms.Compose([\ntransforms.ToTensor(),\ntransforms.Normalize(IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD)])","metadata":{"execution":{"iopub.status.busy":"2024-01-23T15:23:25.465189Z","iopub.execute_input":"2024-01-23T15:23:25.465659Z","iopub.status.idle":"2024-01-23T15:23:25.472533Z","shell.execute_reply.started":"2024-01-23T15:23:25.465617Z","shell.execute_reply":"2024-01-23T15:23:25.471523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"threashold_1 = 0.7\nthreashold_2 = 0.15\nthreashold_3 = 5\nthreashold_4 = 0.1\nthreashold_5 = 0.15\nthreashold_6 = 5\n\n\ndef cosine_sim(x, y):\n    return torch.nn.functional.cosine_similarity(x, y)\n\n\ndef aesthetic_score(x, device):\n    x = transform(x).to(device)\n    if device == 'cuda:0':\n        return aes_metric1(x)\n    return aes_metric2(x)\n\n\ndef generate_seed_from_prompt(prompt):\n    return zlib.adler32(prompt.encode())\n\n\ndef check(prompt_sticker,image_sticker, prompt,image, device):\n    '''\n    Example:\n    prompt_sticker = \"A sticker of ferrari f1\"\n    image_sticker = pipe1('A sticker of ferrari f1', guidance_scale=5).images[0]\n    prompt = \"A photo of ferrari f1\"\n    image = \"pipe1('A photo of ferrari f1', guidance_scale=5).images[0]\"\n    device = \"cuda:0\"\n    '''\n    image_preprocessed = processor(images=image, return_tensors=\"pt\").to(device)\n    prompt_preprocessed = processor(text=prompt, return_tensors=\"pt\", padding=\"max_length\").to(\n        device)\n    image_sticker_preprocessed = processor(images=image_sticker, return_tensors=\"pt\").to(device)\n    prompt_sticker_preprocessed = processor(text=prompt_sticker, return_tensors=\"pt\", padding=\"max_length\").to(device)\n\n    prompt_is_sticker_preprocessed = processor(text='A photo of a sticker.', return_tensors=\"pt\", padding=\"max_length\").to(device)\n    prompt_has_face_preprocessed = processor(text='photo contains human face', return_tensors=\"pt\", padding=\"max_length\").to(device)\n    \n    with torch.no_grad():\n        if device == 'cuda:0':\n            image_emb = clip_model1.get_image_features(**image_preprocessed).to(device)\n            image_sticker_emb = clip_model1.get_image_features(**image_sticker_preprocessed).to(device)\n\n            prompt_emb = clip_model1.get_text_features(**prompt_preprocessed).to(device)\n            prompt_sticker_emb = clip_model1.get_text_features(**prompt_sticker_preprocessed).to(device)\n            prompt_is_sticker_emb = clip_model1.get_text_features(**prompt_is_sticker_preprocessed).to(device)\n            prompt_has_face_emb = clip_model1.get_text_features(**prompt_has_face_preprocessed).to(device)\n        else:\n            image_emb = clip_model2.get_image_features(**image_preprocessed).to(device)\n            image_sticker_emb = clip_model2.get_image_features(**image_sticker_preprocessed).to(device)\n\n            prompt_emb = clip_model2.get_text_features(**prompt_preprocessed).to(device)\n            prompt_sticker_emb = clip_model2.get_text_features(**prompt_sticker_preprocessed).to(device)\n            prompt_is_sticker_emb = clip_model2.get_text_features(**prompt_is_sticker_preprocessed).to(device)\n            prompt_has_face_emb = clip_model2.get_text_features(**prompt_has_face_preprocessed).to(device)\n\n    x1 = cosine_sim(image_emb, image_sticker_emb).cpu().detach().numpy()[0]\n    x2 = cosine_sim(image_sticker_emb, prompt_sticker_emb).cpu().detach().numpy()[0]\n    x3 = aesthetic_score(image_sticker, device).cpu().detach().numpy()[0][0]\n    x4 = cosine_sim(image_sticker_emb, prompt_is_sticker_emb).cpu().detach().numpy()[0]\n    x5 = cosine_sim(image_emb, prompt_emb).cpu().detach().numpy()[0]\n    x6 = aesthetic_score(image, device).cpu().detach().numpy()[0][0]\n    x7 = cosine_sim(image_emb, prompt_has_face_emb).cpu().detach().numpy()[0]\n    \n    return {'x1':x1, 'x2':x2, 'x3':x3, 'x4':x4, 'x5':x5, 'x6':x6, 'x7':x7}\n        \n    \ndef get_rand_gen(prompt, device):\n    rnd_seed = generate_seed_from_prompt(prompt)\n    return torch.Generator(device).manual_seed(rnd_seed), rnd_seed\n\n\ndef get_pair_data(prompt_sticker, device):    \n    prompt = prompt_sticker.replace('A sticker', 'A photo', 1)\n    generator, rnd_seed = get_rand_gen(prompt, device)\n    \n    if device == 'cuda:0':\n        image_sticker = pipe1(prompt_sticker, guidance_scale=5, generator=generator).images[0]\n        image = pipe1(prompt, guidance_scale=5, generator=generator).images[0]\n    else:\n        image_sticker = pipe2(prompt_sticker, guidance_scale=5, generator=generator).images[0]\n        image = pipe2(prompt, guidance_scale=5, generator=generator).images[0]\n    \n    info = check(prompt_sticker,image_sticker, prompt,image, device)\n    return (prompt_sticker,image_sticker, prompt,image,rnd_seed,info)\n\n\ndef runner(prompt_stickers, device):\n    global result\n    \n    for prompt_sticker in tqdm(prompt_stickers):\n        if (stop_t1 and device == 'cuda:0') or (stop_t2 and device == 'cuda:1'):\n            return\n        \n        data = get_pair_data(prompt_sticker, device)\n        result.append(data)","metadata":{"execution":{"iopub.status.busy":"2024-01-23T15:23:25.474174Z","iopub.execute_input":"2024-01-23T15:23:25.474609Z","iopub.status.idle":"2024-01-23T15:23:25.497419Z","shell.execute_reply.started":"2024-01-23T15:23:25.474573Z","shell.execute_reply":"2024-01-23T15:23:25.496467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#костыль, выключается не сразу, а когда 2 картинки сгенерятся и пройдут проверки ласт картинки\n#t.is_alive() проверить\nstop_t1, stop_t2 = False, False\n\nresult = []\nprompts = df['prompt'][:2]\nprompts1, prompts2 = prompts[:len(prompts) // 2], prompts[len(prompts) // 2:]\nt1 = threading.Thread(target=runner, args=(prompts1, 'cuda:0'))\nt2 = threading.Thread(target=runner, args=(prompts2, 'cuda:1'))\nt1.start()\nt2.start()\ntry:\n    t1.join()\n    t2.join()\nexcept KeyboardInterrupt:\n    stop_t1 = True\n    stop_t2 = True","metadata":{"execution":{"iopub.status.busy":"2024-01-23T15:23:25.498727Z","iopub.execute_input":"2024-01-23T15:23:25.499065Z","iopub.status.idle":"2024-01-23T15:24:55.910410Z","shell.execute_reply.started":"2024-01-23T15:23:25.499038Z","shell.execute_reply":"2024-01-23T15:24:55.909423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir imgs","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"table_to_upd = 'table1'\n\n#остановить gen_id\n#(prompt_sticker,image_sticker, prompt,image,info)\n\nfor prompt_sticker, image_sticker, prompt,image, rnd_seed, info in result:\n    data = {'prompt_sticker':prompt_sticker, 'image_sticker':f'{prompt_sticker}_{rnd_seed}.png', 'image':f'{prompt}_{rnd_seed}.png', 'metrics':info}\n    db.child(table_to_upd).push(data)\n    image.save(os.path.join('imgs', data['image']))\n    image_sticker.save(os.path.join('imgs', data['image_sticker']))","metadata":{"execution":{"iopub.status.busy":"2024-01-23T15:24:55.911746Z","iopub.execute_input":"2024-01-23T15:24:55.912046Z","iopub.status.idle":"2024-01-23T15:24:55.916262Z","shell.execute_reply.started":"2024-01-23T15:24:55.912019Z","shell.execute_reply":"2024-01-23T15:24:55.915375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!zip -r imgs_result.zip imgs","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"db.child(\"gen_id\").set(0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"N_display = 5\n\nfor idx, item in enumerate(result[:N_display]):\n    description, img1, photo_desc, img2, metrics = item\n    \n    fig, axs = plt.subplots(1, 2, figsize=(15, 7))\n\n    axs[0].imshow(img1)\n    axs[0].set_title(f'{idx} img; {description}')\n    axs[0].axis('off') \n\n    axs[1].imshow(img2)\n    axs[1].set_title(photo_desc)\n    axs[1].axis('off')\n    \n    plt.figtext(0.5, 0.01, f\"Metrics: {metrics}\", ha=\"center\", fontsize=10)\n\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-01-23T15:24:55.919099Z","iopub.execute_input":"2024-01-23T15:24:55.919505Z","iopub.status.idle":"2024-01-23T15:24:57.825993Z","shell.execute_reply.started":"2024-01-23T15:24:55.919481Z","shell.execute_reply":"2024-01-23T15:24:57.824974Z"},"trusted":true},"execution_count":null,"outputs":[]}]}