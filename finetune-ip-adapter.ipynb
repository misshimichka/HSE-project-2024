{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install diffusers gdown einops >> /dev/null\n!pip install git+https://github.com/tencent-ailab/IP-Adapter.git >> /dev/null","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir image_encoder\n!wget -O \"image_encoder/config.json\" \"https://huggingface.co/h94/IP-Adapter/resolve/main/models/image_encoder/config.json?download=true\"\n!wget -O \"image_encoder/model.safetensors\" \"https://huggingface.co/h94/IP-Adapter/resolve/main/models/image_encoder/model.safetensors?download=true\"\n!wget -O \"image_encoder/pytorch_model.bin\" \"https://huggingface.co/h94/IP-Adapter/resolve/main/models/image_encoder/pytorch_model.bin?download=true\"\n!wget \"https://raw.githubusercontent.com/tencent-ailab/IP-Adapter/main/tutorial_train.py\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!gdown 1EoadqzqXf_dP7Dlkvx3N5I2HVt8Unk_w\n!gdown 18hVvl4bSFM9PV6fLsVwxFVbC1ZFHKzGx","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!unzip images.zip >> /dev/null","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!accelerate launch --mixed_precision \"fp16\" \\\n  tutorial_train.py \\\n  --pretrained_model_name_or_path=\"runwayml/stable-diffusion-v1-5\" \\\n  --image_encoder_path=\"image_encoder\" \\\n  --data_json_file=\"data.json\" \\\n  --data_root_path=\"images\" \\\n  --mixed_precision=\"fp16\" \\\n  --resolution=512 \\\n  --train_batch_size=8 \\\n  --dataloader_num_workers=4 \\\n  --learning_rate=1e-04 \\\n  --weight_decay=0.01 \\\n  --output_dir=\"result\" \\\n  --save_steps=1000","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}